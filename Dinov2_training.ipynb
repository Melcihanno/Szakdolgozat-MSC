{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47144c3a-7df8-4e97-b94a-dc4ebff2d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import SemanticSegmenterOutput  \n",
    "from transformers import Dinov2Model, Dinov2PreTrainedModel  \n",
    "from retouch_dataloader_utils import load_train_and_val  \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from aroi_dataloder_utils import load_val\n",
    "from torch.utils.data import DataLoader  \n",
    "from torch.utils.data import Dataset  \n",
    "import torch.nn.functional as F  \n",
    "from torch.optim import AdamW  \n",
    "from tqdm.auto import tqdm  \n",
    "import albumentations as A \n",
    "from PIL import Image  \n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import torch  \n",
    "import cv2 \n",
    "import csv \n",
    "import os \n",
    "\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Használjon GPU-t a modell tanításához! úgy sokkal gyorsabb...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9062168-888d-4bc4-a865-f039a8597cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset): \n",
    "  def __init__(self, dataset, transform): \n",
    "    self.dataset = dataset \n",
    "    self.transform = transform \n",
    " \n",
    "  def __len__(self): \n",
    "    return len(self.dataset) \n",
    " \n",
    "  def __getitem__(self, idx): \n",
    "    item = self.dataset[idx] \n",
    "\n",
    "    original_image= np.load(item[\"image_path\"])\n",
    "    original_image = np.stack([original_image] * 3, axis=-1)\n",
    "\n",
    "    original_segmentation_map = np.load(item[\"label_path\"])\n",
    "    transformed = self.transform(image=original_image, mask=original_segmentation_map)\n",
    "    image, target = torch.tensor(transformed['image']), torch.LongTensor(transformed['mask']) \n",
    " \n",
    "    image = image.permute(2, 0, 1)\n",
    "    image_path=item[\"image_path\"] \n",
    "      \n",
    "    return image, target, original_image, original_segmentation_map, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274d2f6-3da0-4233-b944-ef49ed58d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(inputs): \n",
    "    batch = dict() \n",
    "    batch[\"pixel_values\"] = torch.stack([i[0] for i in inputs], dim=0) \n",
    "    batch[\"labels\"] = torch.stack([i[1] for i in inputs], dim=0) \n",
    "    batch[\"original_images\"] = [i[2] for i in inputs] \n",
    "    batch[\"original_segmentation_maps\"] = [i[3] for i in inputs]\n",
    "    batch[\"image_path\"] = [i[4] for i in inputs]\n",
    " \n",
    "    return batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941db09e-6eb5-4921-8328-c3518f55b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module): \n",
    "    def __init__(self, in_channels, tokenW=32, tokenH=32, num_labels=1): \n",
    "        super(LinearClassifier, self).__init__() \n",
    " \n",
    "        self.in_channels = in_channels \n",
    "        self.width = tokenW \n",
    "        self.height = tokenH \n",
    "\n",
    "        #Két-réteg:\n",
    "        \n",
    "        #self.conv1 = torch.nn.Conv2d(in_channels, 64, (6,6), padding=1)\n",
    "        #self.conv2 = torch.nn.Conv2d(64, 128, (6,6), padding=1)\n",
    "        #self.classifier = torch.nn.Conv2d(128, num_labels, (1,1))\n",
    "\n",
    "        #Egy réteg:\n",
    "        self.conv = torch.nn.Conv2d(in_channels, 128, (6,6), padding=1)\n",
    "        self.classifier = torch.nn.Conv2d(128, num_labels, (1,1))\n",
    "\n",
    "    def forward(self, embeddings): \n",
    "        embeddings = embeddings.reshape(-1, self.height, self.width, self.in_channels) \n",
    "        embeddings = embeddings.permute(0,3,1,2) \n",
    "\n",
    "        #Két-réteg:\n",
    "        #x = torch.relu(self.conv1(embeddings))\n",
    "        #x = torch.relu(self.conv2(x))\n",
    "        #return self.classifier(x)\n",
    "        \n",
    "        #Egy-réteg\n",
    "        x = torch.relu(self.conv(embeddings))\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee692f37-681d-4050-9a48-77726ea78f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dinov2ForSemanticSegmentation(Dinov2PreTrainedModel): \n",
    "  def __init__(self, config): \n",
    "    super().__init__(config) \n",
    " \n",
    "    self.dinov2 = Dinov2Model(config) \n",
    "    self.classifier = LinearClassifier(config.hidden_size, 32, 32, config.num_labels) \n",
    " \n",
    "  def forward(self, pixel_values, output_hidden_states=False, output_attentions=False, labels=None): \n",
    "    outputs = self.dinov2(pixel_values, \n",
    "                            output_hidden_states=output_hidden_states, \n",
    "                            output_attentions=output_attentions) \n",
    "    patch_embeddings = outputs.last_hidden_state[:,1:,:] \n",
    " \n",
    "    logits = self.classifier(patch_embeddings) \n",
    "    logits = torch.nn.functional.interpolate(logits, size=pixel_values.shape[2:], mode=\"bilinear\", align_corners=False) \n",
    " \n",
    "    loss = None \n",
    "    if labels is not None: \n",
    "      loss_fct = torch.nn.CrossEntropyLoss(ignore_index=0) \n",
    "      loss = loss_fct(logits.squeeze(), labels.squeeze()) \n",
    " \n",
    "    return SemanticSegmenterOutput( \n",
    "        loss=loss, \n",
    "        logits=logits, \n",
    "        hidden_states=outputs.hidden_states, \n",
    "        attentions=outputs.attentions, \n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc524d06-412f-4b70-89c5-1e6f6c0e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(preds, targets, num_classes, smooth=1.0):\n",
    "    preds_softmax = F.softmax(preds, dim=1).float()\n",
    "    targets_one_hot = F.one_hot(targets, num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    # Dice loss számítás\n",
    "    intersection = (preds_softmax * targets_one_hot).sum(dim=(2, 3))\n",
    "    union = preds_softmax.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
    "\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    dice_loss = 1 - dice.mean()\n",
    "    \n",
    "    return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e5675-305b-426a-b489-a0d61cbc39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_coefficient(preds, targets, num_classes, eps=1e-6):\n",
    "    preds_one_hot = torch.nn.functional.one_hot(preds, num_classes).permute(0, 3, 1, 2).float()\n",
    "    targets_one_hot = torch.nn.functional.one_hot(targets, num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    intersection = (preds_one_hot * targets_one_hot).sum(dim=(2, 3))\n",
    "    union = preds_one_hot.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
    "\n",
    "    dice = (2.0 * intersection + eps) / (union + eps)\n",
    "    return dice.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c6708-900e-45cd-af22-e4cdb0d4acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensorboard_writer(logging_dir_name):\n",
    "    return SummaryWriter(log_dir=\"runs/\"+logging_dir_name)  # A logokat ebbe a mappába menti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b161f-5a14-4dd8-8aa1-75e202394524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs,learning_rate,cross_val,train_dataloader):\n",
    "    logging_dir_name=str(epochs)+'_'+str(learning_rate)+'_'+str(cross_val)\n",
    "    writer=create_tensorboard_writer(logging_dir_name)\n",
    "    \n",
    "    model = Dinov2ForSemanticSegmentation.from_pretrained(\"facebook/dinov2-base\", id2label=id2label, num_labels=len(id2label)) \n",
    "     \n",
    "    for name, param in model.named_parameters(): \n",
    "      if name.startswith(\"dinov2\"): \n",
    "        param.requires_grad = False \n",
    "    \n",
    "    learning_rate=float(learning_rate)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    ce_loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "        dice_score_avg = []\n",
    "        loss_avg = []\n",
    "        print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "    \n",
    "            outputs = model(pixel_values, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss_ce = ce_loss_fn(logits.squeeze(), labels.squeeze())\n",
    "    \n",
    "            preds = logits\n",
    "    \n",
    "            loss_dice = dice_loss(preds, labels, num_classes=len(id2label))\n",
    "    \n",
    "            loss = loss_ce + loss_dice\n",
    "            loss_avg.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                preds=logits.argmax(dim=1)\n",
    "                dice_score = compute_dice_coefficient(preds.detach().cpu(), labels.detach().cpu(), num_classes=len(id2label))\n",
    "                dice_score_avg.append(dice_score)\n",
    "                \n",
    "        print(\"Dice score average\",np.nanmean(dice_score_avg))\n",
    "        print(\"Loss average\",np.nanmean(loss_avg))\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", np.nanmean(loss_avg), epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", np.nanmean(dice_score_avg), epoch)\n",
    "        \n",
    "    writer.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67548f-22b0-47af-a22b-8406c20906b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_with_cross_validation(epochs,learning_rates,cross_validation,image_images,label_dir,model_dir):\n",
    "    for epoch in epochs:\n",
    "        for lr in learning_rates:\n",
    "            inference_values = []\n",
    "            for cross_val in range(cross_validation):\n",
    "                dataset = load_train_and_val(image_dir,label_dir,cross_validation,cross_val)\n",
    "\n",
    "                train_dataset = SegmentationDataset(dataset[\"train\"], transform=train_transform)                 \n",
    "                train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0, pin_memory=True,collate_fn=collate_fn)                \n",
    "                model=training(epoch,lr,cross_val,train_dataloader)\n",
    "                logging_model_name=model_dir+'/'+str(epoch)+'_'+str(lr)+'_'+str(cross_val)+'.pth'\n",
    "                torch.save(model.state_dict(),logging_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7e040-26b2-45ea-8fb0-4f13eb728a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0:\"Background\",\n",
    "    1:\"IRF\",\n",
    "    2:\"SRF\",\n",
    "    3:\"PED\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22448d42-a38e-4b47-96e4-45aacac4d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADE_MEAN = (np.array([123.675, 116.280, 103.530])).tolist()\n",
    "ADE_STD = (np.array([58.395, 57.120, 57.375])).tolist()\n",
    " \n",
    "train_transform = A.Compose([ \n",
    "    A.Resize(width=448, height=448),\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
    "], is_check_shapes=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0bbb8-2c34-4857-aba3-b716d00f352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '.../RETOUCH_TRAINING/imagesTr'\n",
    "label_dir = '.../RETOUCH_TRAINING/labelsTr'\n",
    "model_dir = '.../modellek/'\n",
    "\n",
    "\n",
    "epochs=[5,10,100]\n",
    "learning_rates=['1e-2','1e-3','1e-4','1e-5']\n",
    "cross_validation=5\n",
    "run_train_with_cross_validation(epochs,learning_rates,cross_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
